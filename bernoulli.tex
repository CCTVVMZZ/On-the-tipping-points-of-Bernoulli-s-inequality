% -*- mode: latex; eval: (flyspell-mode 1); ispell-local-dictionary: "american"; TeX-master: t; -*-

\documentclass[12pt]{article}



\usepackage{hyperref,amsthm,amsmath,amsfonts} 

\newcommand{\bZ}{\mathbb{Z}} 
\newcommand{\bR}{\mathbb{R}} 
\newcommand{\bN}{\mathbb{N}}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\gtint}[1]{\left] #1, \infty \right[}
\newcommand{\geint}[1]{\left[ #1, \infty \right[}
\newcommand{\ltint}[1]{\left]- \infty, #1 \right[}
\newcommand{\leint}[1]{\left]- \infty, #1 \right]}

\newcommand{\ttx}{\mathtt{x}}
\newcommand{\ttz}{\mathtt{z}}
\newcommand{\tty}{\mathtt{y}}

\newtheorem{theorem}{Theorem}
% \newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}

\begin{document}

\title{On the tipping points of Bernoulli's inequality}
\author{Charlot Colmes}
\maketitle 

\sloppy

Let $V$ be a normed vector space.
For each $v \in V$, the norm of $v$ in $V$ is denoted by $\norm{v}$ as usual.

\begin{theorem}[Mean value inequality \cite{Coleman-calculus}] \label{thm:mvi}
  Let $a$, $b \in \bR$ be such that $a \le b$,
  let $f\colon [a, b] \to V$, and let $g\colon [a, b] \to \bR$ be such that
  \begin{enumerate}
  \item both $f$ and $g$ are continuous on $[a, b]$,
  \item both $f$ and $g$ are differentiable on $\left]a, b \right[$, and
  \item inequality $\norm{f'(x)} \le g'(x)$ holds true for every $x \in \left]a, b \right[$.
  \end{enumerate}
  Inequality
  \begin{equation} \label{eq:mvi-f-g}
    \norm{f(b) - f(a)} \le g(b) - g(a) 
  \end{equation} 
  holds true.
\end{theorem}

\begin{lemma} \label{lem:mvi}
  Let the notation be as in Theorem~\ref{thm:mvi}.
  Inequality~\eqref{eq:mvi-f-g} holds true
  if both $f$ and $g$ are differentiable at $a$
  and
  if $\norm{f'(x)} < g'(x)$ for every $x \in \left[a, b \right[$.  
\end{lemma}

\begin{proof}
  Put
  $$
  X = \left\{ x \in [a, b] : \norm{f(x) - f(a)}  \le g(x) - g(a) \right\} \, .
  $$
  Our task is to prove $b \in X$.
  Put $c = \sup X$.  %(\emph{a priori} $c = \pm \infty$ is possible).
  We first check $c \in X$ and then $b = c$.
  Since $a \in X$ and since $b$ is an upper bound for $X$,
  $c$ is
  an element of $[a, b]$
  and
  a closure point of $X$ in $\bR$ \cite{RudinPrinciples}.
  Besides, $X$ is closed in $[a, b]$ because $f$ and $g$ are continuous on that interval.
  It follows $c \in X$.
  %Since $[a, b]$ is closed in $\bR$, $X$ is also closed in $\bR$, and thus $c$ is an element of~$X$.
  Now, let $x \in X$ with $x < b$.
  The final step is to rule out $c = x$.
  Since $\norm{f'(x)} < g'(x)$,
  there exists $y \in \left]x, b\right[$ such that
  $$
  \norm{\frac{f(y)  - f(x)}{y - x}} < \frac{g(y) - g(x)}{y - x}  \, .
  $$
  It follows 
  \begin{align*}
    \norm{f(y) - f(a)}
    & \le \norm{f(y) - f(x)} + \norm{f(x) - f(a)} \\
    & \le g(y) - g(x) + g(x) - g(a)   \\
    & = g(y) - g(a)  \,, 
  \end{align*}
  whence $y \in X$.
  Therefore, $x$ is not an upper bound for $X$, and thus $c$ is not equal to~$x$.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:mvi}]
  % Put $I = \left]a, b \right[$.
  % Let  $u$, $v \in I$ be such that $u < v$ and
  Let $\alpha \in \left]a, b \right[$ and let  $\varepsilon \in \gtint{0}$.
  Let $g_\varepsilon \colon [a, b] \to \bR$ be defined by: $g_\varepsilon(x) = g(x) + \varepsilon x$ for every $x \in [a, b]$.
  Both $f$ and $g_\varepsilon$ are continuous on $[\alpha, b]$ and 
  both $f$ and $g_\varepsilon$ are differentiable on $\left[\alpha, b \right[$.
  Moreover, we have 
  $$
  \norm{f'(x)} \le g'(x) < g'(x) + \varepsilon =  g'_\varepsilon(x)
  $$
  for every $x \in \left]a, b \right[$.
  Therefore, Lemma~\ref{lem:mvi} ensures 
  \begin{equation} \label{eq:mvi-alpha-beta-eps} 
  \norm{f(\alpha) - f(b)} \le g_\varepsilon(\alpha) - g_\varepsilon(b) \, .
\end{equation}
%for every $\alpha \in \left]a, b \right[$.
  Now, let $\alpha$ and $\varepsilon$ approach $a$ and $0$, respectively.
  Then, Equation~\eqref{eq:mvi-alpha-beta-eps} yields Equation~\eqref{eq:mvi-f-g},
\end{proof}
\bibliographystyle{plain}
\bibliography{bernoulli}

\end{document} 

\begin{lemma} \label{lem:mvi}
  Let $I$ be an interval of $\bR$,
  %let $V$ be a normed vector space,
  let $f\colon I \to V$, and let $g\colon I \to \bR$ be such that
  $f$ and $g$ are both differentiable and $\norm{f'(x)} < g'(x)$ for every $x \in I$.
  For every $a$, $b \in I$, $a \le b$ implies
\end{lemma}

\begin{proof}
  Let $a$, $b \in I$ be such that $a < b$.
\end{proof} 



\begin{theorem}
  Let $I$ be a real interval,
  let $V$ be a normed vector space,
  let $f\colon I \to V$, and let $g\colon I \to \bR$ be such that
  $f$ and $g$ are differentiable and $\norm{f'(x)} \le g'(x)$ for every $x \in I$.
  For every $a$, $b \in I$, $a < b$ implies
  $$\norm{f(b) - f(a)} \le g(b) - g(a) \, . $$
\end{theorem}

\begin{proof}
  Let $a$, $b \in I$ be such that $a < b$ and let $\varepsilon \in \gtint{0}$ be fixed.
  Put
  $$
  X = \left\{ x \in [a, b] : \norm{f(x) - f(a)}  \le g(x) - g(a) + (x - a) \varepsilon \right\} \, .
  $$
  Our task is to prove $b \in X$.
  Put $c = \sup X$.
  Since $X$ contains $a$ as an element and since $b$ is an upper bound for $X$,
  $c$ is a real number, and thus $c$ is a point of closure of~$X$.
  Besides, $X$ is closed in $[a, b]$ because $f$ and $g$ are continuous.
  It follows $c \in X$. 
  By the way of contradiction, assume $c < b$.
  Since $\norm{f'(c)} \le g'(c)$,
  there exists $d \in \left]c, b\right]$ such that
  $$
  \norm{\frac{f(d)  - f(c)}{d - c}} \le \frac{g(d) - g(c)}{d - c} + \varepsilon \, .
  $$
  It follows 
  \begin{align*}
    \norm{f(d) - f(a)}
    & \le \norm{f(d) - f(c)} + \norm{f(c) - f(a)} \\
    & \le g(d) - g(c) + (d - c) \varepsilon + g(c) - g(a) + (c - a) \varepsilon  \\
    & = g(d) - g(a) + (d - a) \varepsilon \,, 
  \end{align*}
  whence $d \in X$: contradiction.
\end{proof} 

$$
g(x) = f(x) - \sum_{j = 0}^n \frac{x^j}{j!} f^{k}(0)
$$

$k = 0$, $1$.

$$
g_0' = g_1
$$

$$
g_0(0) = 0
$$

$$
xg_{n - 1}(x) = f^{(n - 1)}(x) - f^{(n - 1)}(0) - x f^{(n)}(0)
$$

Let $\ttz$ be a formal variable over the complex numbers.
Put
$$
B_n(\ttz) = {(1 + \ttz)}^n - 1 - n \ttz 
$$
for every $n \in \bN$.

Put
\begin{equation} \label{eq:E-expansion}
E(\ttz) = \sum_{n = 1}^\infty \frac{1}{n!} \ttz^{n - 1} \, .
\end{equation}
% or equivalently, 
% $$
% E(\ttz) = \frac{\exp(\ttz) - 1}{\ttz} \, . 
% $$
The formal power series $E$ converges everywhere on the complex plane and is completely determined by:
%satisfies $E(0) = 1$ and 
\begin{equation} \label{eq:def-func-E}
\exp(\ttz) = 1 + \ttz E(\ttz) \, . 
\end{equation} 
Let $F\colon \bR \times \gtint{0} \to \bR$ be defined by:
\begin{equation} \label{eq:def-F}
F(x, y) =  E((x - 1)( \ln y)) (\ln y) y  - y
\end{equation}
for every $x \in \bR$ and every $y \in \gtint{0}$.
Clearly, $F$ is smooth and completely determined by:
\begin{equation} \label{eq:F-y-lny-y}
F(1, y) = y \ln y - y
\end{equation}
and 
\begin{equation} \label{eq:F-yx-xy}
  (x - 1)F(x, y)  = y^x - x y
\end{equation}
for every $x \in \bR$ and every $y \in \gtint{0}$.
%(Equation~\eqref{eq:F-yx-xy} follows from Equation~\eqref{eq:def-func-E}).
For each odd $n \in \bN$ and every $t \in \bR$, $F$ and $B_n$ are related by
\begin{equation} \label{eq:B-F}
B_n(- 1 - t) = (n - 1) (1 - F(n, t)) \, .
\end{equation} 

\begin{lemma} \label{lem:Eprime}
  The derivative of $E$ is positive on~$\bR$.
\end{lemma}

\begin{proof}
  Equation~\eqref{eq:E-expansion} yields $E'(0) = \frac{1}{2}$.
  Now, let  $x \in \bR \setminus \{ 0 \}$ be fixed.
  Our task is to prove $E'(x) > 0$.
  Put $D(\ttz) = \ttz^2 E'(\ttz)$. 
  By differentiating  Equation~\eqref{eq:def-func-E} twice, we obtain 
  $$
  \exp(\ttz) = E(\ttz) + \ttz E'(\ttz) \,, 
  $$
  and subsequently 
  $$
  \exp(\ttz) = 2 E'(\ttz) + \ttz E''(\ttz)  \,.
  $$
  It follows
  $$
  \ttz \exp(\ttz) = 2 \ttz E'(\ttz ) + \ttz^2 E''(\ttz) = D'(\ttz) \,,
  $$
  whence $D'$ is negative on $\ltint{0}$ and positive on $\gtint{0}$.
 % and thus the sign of $D'(x)$ is equal to that of~$x$.
  Therefore, we have $D(x) > D(0)$.  
  Since $D(0) = 0$ and since $D(x) > 0$ is equivalent to $E'(x) > 0$,
  $E'(x)$ is positive.
\end{proof}

\begin{lemma}
  The partial derivative of $F$ with respect to its first variable is positive.
\end{lemma}

\begin{proof}
  By differentiating Equation~\eqref{eq:def-F} with respect to $x$, we obtain
  $$
  \partial_1 F(x, y) = E'((x - 1) \ln y) \ln^2 y 
  $$
  for every $x \in \bR$ and every $y \in \gtint{0}$.
  Therefore, the desired result follows from Lemma~\ref{lem:Eprime}
\end{proof} 

\begin{theorem}
  There exists a unique smooth $\sigma \colon \gtint{1} \to \gtint{0}$ such that
  for every $x \in \bR$ and every $y \in \gtint{1}$, the sign of $F(x, y)$ is equal to that of $x - \sigma(y)$.
\end{theorem}

\begin{lemma}
  The partial derivative of $F$ with respect to its second variable is
  negative on $\bR \times \ltint{1}$
  and
  positive on $\bR \times \gtint{1}$.
\end{lemma} 

\begin{proof}
\end{proof} 



If $n$ is odd and if $t \in \gtint{0}$
$$
f_n(- 1 - t)
%= - t^n - 1 + n + n t
= - F(n, t) 
$$
Let $F\colon \bR \times \gtint{0}\to \bR$ be defined by:
$$
F(x, y) = y^x - x y - x + 1
$$
for every $x \in \bR$ and every $y \in \gtint{0}$.
For each $i \in \{ 1, 2 \}$, let $\partial_i F$ denote the $i$th partial derivative of~$F$:
$$
\partial_1 F(x, y) = y^x \ln y - y - 1 
$$
and
\begin{equation} \label{eq:dF-dy}
\partial_2 F(x, y) =  (y^{x - 1}  -  1) x
\end{equation} 
for every $x \in \bR$ and every $y \in \gtint{0}$.

\begin{theorem}
  There exists a (unique) smooth function $\tau\colon \gtint{0} \to \gtint{1}$ such that
  for every $x$, $y \in \gtint{0}$,
  the sign of $F(x, y)$ is equal to that of $(x - 1)(y - \tau(x))$.
\end{theorem}

\begin{proof}
  % For every $x \in \bR$ and every $y \in \gtint{0}$,
  % the sign of $\partial_2 F(x, y)$ is equal 
  Let $x \in \gtint{1}$ be fixed.
   Equation~\eqref{eq:dF-dy} shows that
  the sign of $\partial_2F(x, y)$ is equal to that of $y - 1$ for every $y \in \gtint{0}$.
  Therefore, $F(x, \cdot)$ is decreasing on $\left[0, 1 \right]$ and increasing on $\geint{1}$.
  Besides, we have $$
  F(x, 0) = 1 - x < 0 < \infty = \lim_{y \to \infty} F(x, y) \, .
  $$
  
\end{proof}
Straightforward computations yield:
$$
F(x, y) = - x F(x^{-1}, y^x) 
$$
for every $x \in \bR \setminus \{ 0 \}$ and every $y \in \gtint{0}$.
It follows 
\begin{equation} \label{eq:tau-x-tau-x}
\tau(x^{- 1}) = \left( \tau(x) \right)^x 
\end{equation}
for every $x \in \gtint{0}$.

\begin{theorem}
  The derivative of $\tau$ is positive.
\end{theorem}

\begin{proof}
  Let us first prove $\tau'(1) > 0$.
  Differentiating Equation~\eqref{eq:tau-x-tau-x} with respect to $x$ yields
  $$
  -x^{-2} \tau'(x^{-1}) = x \left(\tau(x) \right)^{x - 1} \tau'(x) + \left( \tau(x) \right)^x  \ln \tau(x) 
  $$
  for every $x \in \gtint{0}$, so in the particular case where $x = 1$, we get  
  $$
  - \tau'(1) =  \tau'(1) + \tau(1) \ln \tau(1) \,, 
  $$
  or equivalently,
  $$
  2 \tau'(1) = - \tau(1) \ln  \tau(1)  \,.
  $$
  Besides, the latter quantity is obviously negative.
  
  %The derivatives of $\tau(x^{-1})$ and $\left( \tau(x) \right)^x$ with respect to $x$ are equal to
  % $- x^{-2} \tau'(x^{-1})$ and
  % $$
  % -x^{-2} \tau'(\left( \tau(x) \ln \tau(x) + x \tau'(x) \right) 
  % \left(\tau(x) \right)^{x - 1} \,, 
  % $$
  % respectively.
  
  %   It follows $\tau'(1) = 
\end{proof} 

Straightforward computations yield 
$$
F(x, y) = (x - 1) \left( E((x - 1) \ln y) y \ln y - y - 1  \right)
$$
for every $(x, y) \in \Omega$.
% $F(x, y) = 0$ is equivalent to
% $$
% y = \exp \left( \frac{ \ln(2 x) }{x} + \frac{1}{x} \ln \left( \frac{1 + y}{2}  - \frac{1}{2x}  \right) \right) 
% $$

\begin{theorem}
  Inequality $x \tau(x) > 2$ holds true for every $x \in \left]0, 2e^{-1} \right]$
  and $x \tau(x)$ approaches $2$ as $x$ approaches~$0$.
\end{theorem} 

\begin{proof}
  Let $x \in \left]0, 2 e^{-1} \right[$.
  We have 
  %$2 x^{-1} \ge e$, or equivalently,
  $\ln(2 x^{-1}) \ge 1$.
  It follows
  $$
  F(x, 2x^{-1})
  = \exp (x \ln(2 x^{-1})) - x - 1 
  \ge 1 + x \ln(2 x^{-1}) - x - 1
  = \left(\ln(2 e^{-1}) - \ln  x \right) x > 0\,, 
  $$
  whence $\tau(x) > 2 x^{-1}$.

  $$
  F(x, (2 + \epsilon) x^{-1}) = \exp(x \ln(2 + \epsilon) - x \ln x) - x - 1 - \epsilon
  $$
\end{proof}
$$
2^xx^{-x} \ge  x + 1
$$

$$
x^{-1}  \ln(1 + x) \le 1 \le \ln (2x^{-1}) 
$$

$$
0 \le \ln(2 x^{-1} ) - x^{-1} \ln( 1 + x) = x^{-1} \ln \left( 2^x x^{-x} {(1 + x)}^{-1} \right)
$$

$$
1 \le 2^x x^{- x} {(1 + x)}^{-1} 
$$
\begin{lemma}
  For each 
\end{lemma}
\begin{lemma}
  There exists a unique $t \in \gtint{1}$ such that $t \ln t = t + 1$.
\end{lemma}

\begin{proof}
  Let $f\colon \geint{1} \to \bR$ be defined by:
  $f(x) = x \ln x - x - 1$ for every $x \in \geint{1}$.
  Since $f(1) = - 1 < 0 < e^2 - 1 = f(e^2)$, 
  the intermediate value theorem ensures that there exists $t \in \left]1, e^2 \right[$ such that
  $f(t) = 0$.
  Since $f'$ is the restriction of $\ln$ to $\geint{1}$,
  $f$ is increasing, and thus $t$ is the unique zero of~$f$.
%  By construction, $t$ satisfies the desired properties.
\end{proof}

\begin{theorem}
  For each $x \in \gtint{0}$,
  there exists $t \in \gtint{1}$ such that for every $y \in \gtint{0}$,
  the sign of $F(x, y)$ is equal to that of $(x - 1) (y - t)$.
\end{theorem}

\begin{proof}
  The case where $x = 1$ is trivial.
  Let us now assume $x > 1$.
 
  Then, we have $F(x, y) = 0 = (x - 1) (y - t)$   every $y \in \gtint{0}$,
  and thus 
  the case where 
  Let us fist consider the case where $x = 1$.
  
\end{proof} 

\begin{proof}
  Let $x \in \left]0, 1\right[ \cup \gtint{1}$ be fixed.
  First, assume $x \in \gtint{1}$.
  Let $f \colon \geint{1} \to \bR$ be defined by:
  $f(y) = F(x, y)$ for every $y \in \geint{1}$.
  Both
  $y^{x - 1}$ and
  $$
  y^{-1} f(y) = y^{x - 1} - x - x y^{-1} + y^{-1} = \exp \left( (x - 1) \ln y \right) - x - x y^{-1} + y^{- 1}
  $$
  $$
  F(x, \exp x) = \exp( x^2) - x \exp x - x + 1  
  $$
  approach $\infty$
  as $y$ approaches $\infty$,
  whence $\lim_{y \to \infty} f(y) = \infty$.
  Besides, $f(1) = 2 - 2x$ is negative,
  so the intermediate value theorem ensures that there exists $t \in \gtint{1}$ such that $f(t) = 0$.
  Since 
  $f'(y) = x (y^{x - 1} - 1)$ for every $y \in \geint{1}$,
  $f'$ is positive on $\gtint{1}$,
  and thus $f$ is increasing.
  Therefore, $t$ is the unique zero of~$f$.
\end{proof}

\begin{theorem}
  There exists a unique function $\tau \colon \gtint{0} \to \gtint{1}$ such that
  $F(x, \tau(x)) = 0$ for every $x \in \gtint{0}$ and $\tau(1) \ln \tau(1) = \tau(1) + 1$.
\end{theorem}

\begin{proof}
  Let us first deal with the case where $x = 1$.
  %Hence, $f$ has exactly one zero  and that zero is greater than~$1$. 
  Since $F(1, y) = 0$ for every $y \in \gtint{0}$,
  the zero of $f$ is the unique suitable choice for $\tau(1)$.

  Second, let $x \in \gtint{1}$ be fixed.
  Hence, $g$ has exactly one zero and that zero is the unique suitable choice for $\tau(x)$.

   $\tau(x^{-1})$ to the power of $x^{-1}$ is the unique suitable choice for $\tau(x)$.
\end{proof} 

%Note that $F$ not less that $1$ on $\leint{0} \times \gtint{0}$ and that
We claim that the zero set of $F$ is equal to
$$
\left\{ (x, \tau(x)) : x \in \gtint{0} \right\} \cup (\{ 1 \} \times \bR)  \,;
$$
the verification is left to the reader.

\begin{theorem}
  The function $\tau$ is smooth.
\end{theorem}

\begin{proof}
  Let $G \colon \bR \times \gtint{0} \to \bR \times \bR$ be defined by:
  $G(x, y) = (x, F(x, y))$ for every $x \in \bR$ and every $x \in \gtint{0}$. 
\end{proof}

\begin{theorem}
  For each $x \in \left]0, 1 \right[ \cup \gtint{1}$,
  there exist a unique $y \in \gtint{1}$ such that $F(x, y) = 0$.
\end{theorem}

\begin{theorem}
  There exists a unique function $\tau\colon  \gtint{1} \to \gtint{1}$ such that
  $F(x, \tau(x)) = 0$ for every $x \in \gtint{1}$.
\end{theorem}

\begin{proof}
  Let $x \in \left] 0, 1 \right[ \cup \gtint{1}$.
  $$
   F(x, 1) = 2 - 2 x 
  $$

   
\end{proof}

\begin{proof}
  Let $y \in \gtint{1}$ be fixed.
  For each $x \in \bR$,
  the basic rules of derivation  yield 
$$
\partial_1 F(x, y) = y^x \ln y - y - 1 \,, 
$$
whence $\partial_1 F(x, y) = 0$ is equivalent to 
$$
x  = \frac{\ln (y + 1) - \ln \ln y}{\ln y} \, . 
$$
In particular, equality $\partial_1 F(x, y) = 0$ holds true for exactly one $x \in \bR$,
and thus Rolle's theorem ensures that there exist at most two distinct $x \in \bR$ for which $F(x, y) = 0$.
Since $F(1, y) = 0$, there exists at most $x \in \gtint{1}$ such that $F(x, y) = 0$.




\end{proof}



Let
$$
G(x, y) = (x, F(x, y))
$$

$$
J_G(x, y)
=
\begin{bmatrix}
    1  &  0 \\ 
    y^x \ln y - y - 1
    &  x (y^{x - 1} - 1) 
\end{bmatrix}
$$
$$
F(2, 3)  = F(3, 2) =  0
$$


$$
F(x, 1) = 2 - 2x < 0
$$ 

$$
F(x, 2) = 2^x - 3 x + 1
$$
\begin{theorem}
  There exists a unique function $\tau \colon \gtint{1} \to \gtint{0}$ such that
  $$
  \exp\left( x \tau(x) \right)  - x \exp  \tau(x) = x - 1
  $$
  for every $x \in \gtint{1}$.
\end{theorem}

\begin{proof}
  Let $x \in \gtint{1}$ be fixed.
  Let $f\colon $
\end{proof}


\end{document}


Let $\bR$ denote the field of real numbers,
let $\bN$ denote the set of all \emph{non-negative} integers, and 
let $\ttx$ be an indeterminate over~$\bR$.

\section{Introduction}

The paper focuses on the sequence  of polynomials $\left( f_n \right)_{n \in \bN}$ given by:
$f_n(\ttx) = \ttx^n  - n \ttx$ for each $n \in \bN$.
% The first five terms are:
% $f_0(\ttx) = f_1(\ttx) = 0$,
% $f_2(\ttx) = \ttx^2$,
% $f_3(\ttx) = \ttx^3 + 3 \ttx^2$, and
% $f_4(\ttx) = \ttx^4 + 4 \ttx^3 + 6 \ttx^2$.
The fundamental property of the $f_n$'s is that
the following equivalence holds true for every $n \in \bN$ and every $x \in \bR$:
$$
f_n(x + 1) \ge n - 1 \iff {(1 + x)}^n \ge 1 + n x \,.
$$ 
The latter inequality is called \emph{Bernoulli's inequality}.
Hence, studying Bernoulli's inequality is studying the signs of the $f_n$'s.
It turns out that the behavior of $f_n$ depends on the parity of $n$:


\begin{theorem} \label{thm:variation}
   For each $n \in 2 \bN + 2$,
   $f_n'$ is
   negative on $\ltint{0}$ and
   positive on $\gtint{0}$.
   For each $n \in 2 \bN + 3$, $f_n'$ is
   positive on $\ltint{- 2}$,
   negative on $\left]- 2, 0 \right[$, and
   positive on $\gtint{0}$.
 \end{theorem}

 \begin{proof}
   The basic rules of differentiation yield 
\begin{equation} \label{eq:deriv-fn} 
  f_n'(\ttx)  = n \left( {(1 + \ttx)}^{n - 1} -  1 \right) 
\end{equation}
for each $n \in \bN$,
and thus, the desired result follows from a simple examination of the latter equation.
%Equation~\eqref{eq:deriv-fn}.
\end{proof} 


 \begin{theorem} \label{thm:Bernoulli}
   For each $n \in 2 \bN + 2$,
   $f_n$ is positive on $\bR \setminus \{ 0 \}$. 
   For each  $n \in 2 \bN + 3$,
   there exists $t_n \in  \ltint{-2}$
   such that $f_n$ is
   negative on $\ltint{t_n}$ and
   positive on $\left]t_n,  0\right[ \cup \gtint{0}$.
 \end{theorem}
 
 \begin{proof}
   First, the desired result holds true for $n \in \{ 0, 1 \}$ because $f_0(\ttx) = f_1(\ttx) = 0$.
   Second, assume $n \in  2 \bN + 2$.
   It then follows from Theorem~\ref{thm:variation} that 
   $f_n$ is decreasing on $\leint{0}$ and increasing on $\geint{0}$.
   Therefore, $f_n$ attains its minimum at $0$ and nowhere else. 
   Since $f_n(0) = 0$, $f_n$ is positive on $\bR \setminus \{ 0 \}$.
   Third and last, assume $n \in 2 \bN + 3$.
   It then follows from Theorem~\ref{thm:variation} that
   the restriction of $f_n$ to $\geint{-2}$ attains its minimum at $0$
   and nowhere else.
   Therefore, $f_n$ is positive on $\left[- 2, 0\right[ \cup \geint{0}$.  
   Moreover,
   $f_n(x)$ approaches $- \infty$ as $x$ approaches $- \infty$
   because $f_n$ is a polynomial of odd degree~$n$.
   Hence,
   the intermediate value theorem ensures that there exists $t_n \in \ltint{- 2}$ such that $f_n(t_n) = 0$.
   Since $f_n$ is increasing on $\leint{- 2}$ by Theorem~\ref{thm:variation},
   $f_n$ is negative on $\ltint{t_n}$ and positive on $\left]t_n, - 2 \right]$.
   It follows that $f_n$ is positive on
   $\left]t_n, - 2 \right] \cup \left[- 2, 0 \right[ \cup \gtint{0}
   =
   \left]t_n, 0 \right[ \cup \gtint{0}$,
   as desired.
 \end{proof}
 
 The $t_n$'s are, by definition, the \emph{tipping points} for Bernoulli's inequality.
 Its first term is easy to compute:
 since $f_3$ factors into $f_3(\ttx) = \ttx^2( \ttx + 3)$,
 we have $t_3 = - 3$.
 The aim of this paper is to study the sequence $\left( t_n \right)_{n \in 2 \bN + 3}$.
 Previously known results are examined in Section~\ref{sec:bulgar}:
 % we show that our sequence is increasing
 % and
 % $t_n$ is less than $- 2 - n^{-1}$ for every $n \in 2 \bN + 3$.
 Some improvements are presented in Section~\ref{sec:contrib}.
 % we show $t_n \le - 2 - \ln(2 n) n^{-1}$ is asymptotically equivalent to $(\ln n) / n$ as $n$ approaches~$\infty$.

 
 
 \section{Previous results} \label{sec:bulgar} 

 

 Equation~\eqref{eq:f3-t3} shows that $t_3 = - 3$. 
 \begin{equation} \label{eq:f3-t3}
f_3(\ttx) = \ttx^3 + 3 \ttx^2 = \ttx^2 (\ttx + 3) \,.
\end{equation}



 



 \section{Previous results} 

 In the literature \cite{MitrinovicCNIA, MitrinovicAI, MitrinovicP93, MondP94},
 both Theorems \ref{thm:HP-upper} and \ref{thm:HP-tn-increase} below are attributed to N.~Had\v{z}iivanov and I.~Prodanov.
 
 Straightforward computations yield the following recurrence relation which is used as a lemma:
 \begin{equation} \label{eq:fn+2-fn}
   f_{n + 2} (\ttx) = {(1 + \ttx)}^2 f_n(\ttx) + n \ttx^2 \left(\ttx + 2 + \frac{1}{n} \right)
 \end{equation}
 for every $n \in \bN + 1$.
 
 \begin{theorem} \label{thm:HP-upper}
   For each $n \in 2 \bN + 3$, $t_n$ is not greater than $- 2 - {(n - 2)}^{-1}$.
 \end{theorem}

 \begin{proof}
   Put $u_n = - 2 - n^{-1}$ for every $n \in \bN + 1$.
   Our task it to prove $t_n \le u_{n - 2}$ for every $n \in 2 \bN + 3$.
   We proceed by induction on~$n$.
   Since $f_3(- 3) = 0$,
   we have $t_3 = - 3 = u_3$, 
   
   The assertion holds true for $n = 3$ because $t_3 = u_1 = - 3$.
   Let us now deal with the inductive step.
   Let $n \in 2 \bN + 3$ be such that $t_n \le u_{n - 2}$.
   Since $u_{n - 2}$ not greater than $u_n$, $t_n$ is not greater than $u_n$, or, equivalently, $f_n(u_n)$ is non-negative.
   Therefore,  
   by letting $\ttx = u_n$ in Equation~\eqref{eq:fn+2-fn}, we obtain (note that the rightmost term vanishes)
   $f_{n + 2}(u_n) = {( 1 + u_n )}^2 f_n(u_n) \ge 0$.
   It follows $t_{n + 2} \le u_n$, as desired.
 \end{proof}
 
 
 
\begin{theorem} \label{thm:HP-tn-increase} 
  The sequence $\left( t_n \right)_{n \in 2 \bN + 3}$ is increasing.
 \end{theorem} 

 \begin{proof}
 Let $n \in 2 \bN + 3$.
 By letting $\ttx = t_n$ in Equation~\eqref{eq:fn+2-fn}, we obtain
 $$ 
f_{n + 2} (t_n) = n t_n^2 \left(t_n - 2 - \frac{1}{n} \right) \, .
$$
Besides, Theorem~\ref{thm:HP-upper} ensures that the right-hand side of the latter equality is negative.
It follows $f_{n + 2} (t_n) < 0$ or, equivalently, $t_n < t_{n + 2}$.
\end{proof}

For each $n \in 2 \bN + 5$, $t_n$ lies in $\left]- 3, - 2 \right[$ and the coefficients of $f_n$ are all integers,
so the integral root theorem ensures that $t_n$ is irrational.

\section{Our contribution}

\begin{theorem}
  Let $a \in \gtint{0}$ and let $b \in \bR$.
 As $x$ approaches $\infty$, 
 ${(a x + b)}^{1 / x} - 1$
 and
 $x^{-1} \ln x$ are asymptotically equivalent.
\end{theorem}

\begin{proof}
  
  $$
  {(a x + b)}^{1 / x} - 1 = \exp \left( \frac{\ln (a x + b)}{x} \right) - 1 \ge   \frac{\ln (a x + b)}{x} 
  $$
  
  $$
  \exp(y) = 1 + y + \frac{1}{2} y^2 + O(y^3)  
  $$

  $$
  \ln(1 + y) = O(y) 
  $$

  $$
  \ln(a x + b) = \ln (a x) + \ln \left(1 +  \frac{b}{a x} \right) = \ln(a x) + O \left( \frac{1} {x} \right)
  $$

  $$
   \frac{\ln(ax + b)}{x} = \frac{\ln(a x)}{x} + O \left( \frac{1}{x^2} \right)
  $$
  $$
  {(a x + b)}^{1 / x} = \exp \left( \frac{\ln( a x + b)}{x}  \right) = 1 + 
  $$
\end{proof} 

\begin{proof}
  Put $\epsilon_n = - t_n - 2$: $t_n = - 2 - \epsilon_n$.
  Equality
  $$
  {(1 + t_n)}^n = 1 + n t_n 
  $$
  $$
   {(1 + \epsilon_n)}^n  = - 1 + 2 n + n \epsilon_n 
   $$

   $$
   2 n - 1 \le {(1 + \epsilon_n)}^n  \le  2 n 
   $$

   $$
   \sqrt[n]{2 n - 1} - 1 \le \epsilon_n  \le \sqrt[n]{2 n} - 1
   $$

   $$
   \exp(x) - 1 \ge x
   $$
   $$
   \sqrt[n]{2n - 1} - 1 \ge \frac{\ln(2n - 1)}{n} \sim \frac{\ln(2n)}{n} 
   $$

   $$
   \exp(x) - 1 \sim  x
   $$
   
   $$
   \sqrt[n]{2n \pm 1} - 1 \sim \frac{\ln(2n \pm 1)}{n} \sim \frac{\ln(2n)}{n} 
   $$
   
\end{proof}
Let $n \in \bN$.
Straightforward computations yield
$$
f_n(- 2 - \ttx) = {(- 1)}^n {(1 + \ttx)}^n - 1 + 2n + n \ttx \, , 
$$
whence 
\begin{equation} \label{eq:fn-2-x-odd}
  n \in 2 \bN + 1
  \implies 
 f_n(- 2 - \ttx) = 2n - 2 - f_n(\ttx)   \, .
\end{equation} 
 
\begin{theorem} \label{thm:lower-sqrt}
  For every $n \in 2 \bN + 3$, $t_n$ is not less than $- 2 - 2 / \sqrt{n}$.
\end{theorem}

\begin{proof}
  Let $n \in 2 \bN + 3$.
 Put $\epsilon_n = 2 / \sqrt{n}$.
  Since $\epsilon_n \ge 0$,
  the binomial theorem yields
  $$
  f_n(\epsilon_n ) \ge \frac{1}{2} (n - 1) n \epsilon_n^2 = 2 n - 2 \,.
  $$
  It follows $f_n(- 2 - \epsilon_n) \le 0$ by Equation~\eqref{eq:fn-2-x-odd}, whence $t_n \ge - 2 - \epsilon_n$.
\end{proof} 

Note that Theorem~\ref{thm:lower-sqrt} ensures that $t_n$ approaches $- 2$ as $n$ approaches~$\infty$.


 \bibliographystyle{plain}
 \bibliography{bernoulli}

 \section{Bonus section}
 
\begin{theorem} \label{thm:root-mult}
  For each $n \in \bN + 2$,
  $0$ is a double root of $f_n$ and $0$ the only non-simple (complex) root of $f_n$.
\end{theorem}

\begin{proof}
  Straightforward computations yield the second derivative of $f_n$:
\begin{equation} \label{eq:deriv-second-fn}
f_n''(\ttx)  = n (n - 1) {(1 + \ttx)}^{n - 2} \, .
\end{equation}
  Now, by letting $\ttx = 0$ in Equations \eqref{eq:def-fn}, \eqref{eq:deriv-fn}, and \eqref{eq:deriv-second-fn},
  we obtain 
  $$
  f_n(0) = f_n'(0) = 0 \ne n (n - 1) = f_n''(0) \, ,
  $$
  whence $0$ is a double root of $f_n$.
  In addition, $f_n$ and its derivative satisfy 
   $$
   (1 + \ttx) f_n'(\ttx) - n f_n(\ttx) = n (n - 1) \ttx \, ,
   $$
   so for every complex number $z$, $f_n(z) = f_n'(z) = 0$ implies $z = 0$.
   It follows that $0$ is the only non-simple root of $f_n$.
 \end{proof}
 
%  Theorem~\ref{thm:root-mult} ensures that
% for every $n \in \bN + 2$ and every $x \in \bR$, 
% the graph of $f_n$ \emph{crosses} the $\ttx$-axis at $\ttx = x$ if, and only if, $x$ is a non-zero root of $f_n$
% (the graph of $f_n$ \emph{touches} the $\ttx$-axis at $\ttx = 0$ but does not cross).

\begin{theorem} \label{thm:increasing-fn}
  For each $x \in \left]- 2, 0 \right[ \cup \gtint{0}$,
  the sequence $\left( f_n(x) \right)_{n \in \bN + 1}$ is increasing.
  For each $x \in \bR \setminus \{ 0 \}$,
  the sequence $\left( f_n(x)\right)_{n \in 2 \bN}$ is increasing.
\end{theorem} 

\begin{proof}
 Let $n \in \bN + 1$.
 Straightforward computations yield  
 $$
 f_{n+ 1} (\ttx) - f_n(\ttx) = \frac{1}{n + 1} \ttx  f_{n + 1}'(\ttx) 
 $$
 and
 Theorem~\ref{thm:variation} ensures that $\ttx f_{n + 1}'(\ttx)$ is positive on $\left]- 2, 0 \right[ \cup \gtint{0}$.
 Therefore, the first part of the desired result holds true.
 Now, let $n \in 2 \bN$ and let $x \in \leint{-2}$.
 Straightforward computations yield  
 $$
 f_{n + 2}(\ttx) - f_n(\ttx) =  \left(  (2 + \ttx) {(1 + \ttx)}^n - 2 \right) \ttx
 $$
 and, besides, we have
 $$
  (2 + x) {(1 + x)}^n \le 0 \,, 
 $$
 whence $f_{n + 2}(x) - f_n(x) \ge - 2 x   \ge 4$.
 Therefore, the second part of the desired result holds true.
\end{proof} 

\end{document}

 \begin{theorem}%[Bernoulli's inequality]
   \label{thm:Bernoulli}
   For each $n \in 2 \bN + 2$,
   $f_n(x)$ is positive on $\bR \setminus \{ 0 \}$. 
   For each  $n \in 2 \bN + 3$,
   there exists $t_n \in  \ltint{-2}$
   such that $f_n$ is negative on $\ltint{t_n}$ and positive on $\left]t_n, 0 \right[ \cup \gtint{0}$.
 \end{theorem}
 
 \begin{proof}
   First, assume $n \in  2 \bN + 2$.
   It then follows from Theorem~\ref{thm:variation} that 
   $f_n$ is decreasing on $\leint{0}$ and increasing on $\geint{0}$.
   Therefore, $f_n$ attains its minimum at~$0$ and nowhere else.
   Since $f_n(0) = 0$, $f_n$ is positive on $\bR \setminus \{ 0 \}$.
   Now, assume $n \in 2 \bN + 3$.
   It then follows from Theorem~\ref{thm:variation} that
   the restriction of $f_n$ to $\geint{-2}$ attains its minimum at $0$
   and nowhere else.
   Therefore, $f_n$ is positive on $\left[- 2, 0 \right[ \cup \gtint{0}$.
   Moreover,
   $f_n$ is a polynomial of odd degree $n$, so $f_n(x)$ approaches $- \infty$ as $x$ approaches $- \infty$.
   Hence,
   the intermediate value theorem ensures that there exists $t_n \in \ltint{- 2}$ such that $f_n(t_n) = 0$.
   Since $f_n$ is increasing on $\leint{- 2}$ by Theorem~\ref{thm:variation},
   $f_n$ is negative on $\ltint{t_n}$ and positive on $\left]t_n, - 2 \right]$.
   It follows that $f_n$ is positive on
   $\left]t_n, - 2 \right] \cup \left[- 2, 0 \right[ \cup \gtint{0} = \left]t_n, 0 \right[ \cup \gtint{0}$, as desired.
 \end{proof}

%for every $x \in \bR$: $E(0) = 1$ and 
\begin{equation} \label{eq:E-expansion}
E(x) = \sum_{k = 1}^\infty \frac{1}{n!} x^{n - 1}
\end{equation}
for every $x \in \bR$.

\begin{lemma}
  The derivative of $E$ is positive.
\end{lemma}

\begin{proof}
  Equation~\eqref{eq:E-expansion} yields $E'(0) = \frac{1}{2}$.
  Now, let  $x \in \bR \setminus \{ 0 \}$ be fixed.
  Our task is to prove $E'(x) > 0$.
  Let $E_1$ denote the entire function defined by:  
  $E_1(t) = t^2 E'(t)$ for every $t \in \bR$.
  By differentiating  Equation~\eqref{eq:def-func-E} twice with respect to $x$, we obtain 
  $$
  \exp(x) = E(x) + x E'(x) \,, 
  $$
  and subsequently 
  $$
  \exp(x) = 2 E'(x) + x E''(x)  \,.
  $$
  It follows
  $$
  x \exp(x) = 2 x E'(x) + x^2 E''(x) = E_1'(x) \,,
  $$
  and thus  the sign of $E_1'(x)$ is equal to that of~$x$.
  Therefore, we have $E_1(x) > E_1(0)$.  
  Since $E_1(0) = 0$ and since $E_1(x) > 0$ is equivalent to $E'(x) > 0$,
  $E(x)$ is positive.
\end{proof}

\begin{lemma}
  Let $a$, $b \in [-\infty, \infty]$ be such that $a < b$ and
  let $f\colon \left] a, b \right[ \to \bR$ such that
  $f$ is differentiable and $f'$ has at most one root.
  Both $\lim_{x \to a} f(x)$ and 
  $\lim_{x \to b} f(x)$ exist in $[- \infty, \infty]$.
  If 
  $\lim_{x \to a} f(x)$ and
  $\lim_{x \to b} f(x)$ have opposite signs then $f$ has exactly one root.
\end{lemma}

\begin{proof}
  First, assume that $f'$ does not vanish on $\left] a, b \right[$.
  
  
  Darboux's theorem ensures that 
  First, assume that $f'$ is negative.
  Then, $f$ is increasing, and thus
  % $
  % Second, assume that $f'$ is non-negative.
  % Then, $f$ is increasing
  % % $f'$ is positive on $[a, b] \setminus \{ c \}$,
  % % $f'$ is negative on $[a, b] \setminus \{ c \}$,
  % $f'$ is 
  % $f'$ is negative on $\left]a, c \right[$ and positive on $\left]c, b \right[$,
  % $f'$ is positive on $\left]a, c \right[$ and negative on $\left]c, b \right[$.
  % The intermediate value theorem ensures that $f$ has at least one root.
  % Let $x$, $y \in [a, b]$ be such that $f(x) = f(y) = 0$.
\end{proof}

\begin{lemma}
  Let $a$, $b \in \bR$ be such that $a < b$ and
  let $f\colon [ a, b ] \to \bR$ be differentiable and such that $f'$ has exactly one root.
   then $f$ has at most one root.
\end{lemma}

\begin{proof}
\end{proof}
\begin{lemma}
  Let $f\colon \gtint{0}\to \bR$ be such that
  $f$ is differentiable and $f'$ is increasing.
  Both $\lim_{x \to 0} f(x)$ and $\lim_{x \to \infty} f(x)$ exist in $\bR \cup \{ - \infty , + \infty \}$.
  If $\lim_{x \to 0} f(x)$ or $\lim_{x \o \infty}$ is non-positive then
  
  then there exists $t \in \gtint{0}$ such that for every $x \in \gtint{0}$,
  the sign of $f(x)$ is equal to that of $x - t$.
\end{lemma}

\begin{proof}
  Without loss of generality, we may assume that $f(0)$ is negative and that $f'$ is increasing
\end{proof}